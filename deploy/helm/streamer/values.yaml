replicaCount: 1

image:
  repository: prompted-streamer
  tag: latest
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8082

resources:
  limits:
    memory: 128Mi
    cpu: 100m
  requests:
    memory: 64Mi
    cpu: 50m

config:
  LOG_LEVEL: info
  PORT: "8082"
  MQ_BASE_URL: http://prompted-mqwriter:8084
  STREAMER_CSV_PATH: /data/telemetry.csv
  STREAMER_INTERVAL_MS: "1000"
  STREAMER_CHANNEL_BUFFER: "16"

# ---- CSV Data Source ----
# Option 1 (default): Embed CSV data in a ConfigMap.
#   Set csv.enabled=true and provide csv.data below.
#   An init container copies the ConfigMap into a writable emptyDir
#   at /data so the streamer can update timestamps on disk.
#
# Option 2: Use an external PersistentVolumeClaim.
#   Set csv.enabled=false and pvc.enabled=true.
#   Set pvc.claimName to the name of an existing PVC.
#   The PVC is mounted at the path set in config.STREAMER_CSV_PATH.
csv:
  enabled: true
  data: |
    timestamp,metric_name,gpu_id,device,uuid,model_name,hostname,container,pod,namespace,value,labels_raw
    2024-06-01T12:00:00Z,gpu_utilization,GPU-0a1b2c3d,nvidia0,550e8400-e29b-41d4-a716-446655440001,NVIDIA A100-SXM4-80GB,node-01,train-worker,train-pod-0,ml-prod,87.3,"job=llm-finetune,team=ml-platform"
    2024-06-01T12:00:00Z,gpu_memory_used_bytes,GPU-0a1b2c3d,nvidia0,550e8400-e29b-41d4-a716-446655440002,NVIDIA A100-SXM4-80GB,node-01,train-worker,train-pod-0,ml-prod,68719476736,"job=llm-finetune,team=ml-platform"
    2024-06-01T12:00:00Z,gpu_temperature_celsius,GPU-0a1b2c3d,nvidia0,550e8400-e29b-41d4-a716-446655440003,NVIDIA A100-SXM4-80GB,node-01,train-worker,train-pod-0,ml-prod,72,"job=llm-finetune,team=ml-platform"
    2024-06-01T12:00:00Z,gpu_power_draw_watts,GPU-0a1b2c3d,nvidia0,550e8400-e29b-41d4-a716-446655440004,NVIDIA A100-SXM4-80GB,node-01,train-worker,train-pod-0,ml-prod,295.5,"job=llm-finetune,team=ml-platform"
    2024-06-01T12:00:00Z,gpu_utilization,GPU-5e6f7a8b,nvidia1,550e8400-e29b-41d4-a716-446655440005,NVIDIA H100-SXM5-80GB,node-02,inference-server,infer-pod-0,ml-serving,42.1,"job=llm-serving,team=ml-infra"
    2024-06-01T12:00:00Z,gpu_memory_used_bytes,GPU-5e6f7a8b,nvidia1,550e8400-e29b-41d4-a716-446655440006,NVIDIA H100-SXM5-80GB,node-02,inference-server,infer-pod-0,ml-serving,21474836480,"job=llm-serving,team=ml-infra"
    2024-06-01T12:00:00Z,gpu_temperature_celsius,GPU-5e6f7a8b,nvidia1,550e8400-e29b-41d4-a716-446655440007,NVIDIA H100-SXM5-80GB,node-02,inference-server,infer-pod-0,ml-serving,58,"job=llm-serving,team=ml-infra"
    2024-06-01T12:00:00Z,gpu_power_draw_watts,GPU-5e6f7a8b,nvidia1,550e8400-e29b-41d4-a716-446655440008,NVIDIA H100-SXM5-80GB,node-02,inference-server,infer-pod-0,ml-serving,185.2,"job=llm-serving,team=ml-infra"
    2024-06-01T12:00:00Z,gpu_utilization,GPU-c9d0e1f2,nvidia0,550e8400-e29b-41d4-a716-446655440009,NVIDIA L40S,node-03,batch-processor,batch-pod-0,data-eng,95.8,"job=etl-pipeline,team=data"
    2024-06-01T12:00:00Z,gpu_memory_used_bytes,GPU-c9d0e1f2,nvidia0,550e8400-e29b-41d4-a716-446655440010,NVIDIA L40S,node-03,batch-processor,batch-pod-0,data-eng,42949672960,"job=etl-pipeline,team=data"
    2024-06-01T12:00:00Z,gpu_sm_clock_mhz,GPU-c9d0e1f2,nvidia0,550e8400-e29b-41d4-a716-446655440011,NVIDIA L40S,node-03,batch-processor,batch-pod-0,data-eng,2520,"job=etl-pipeline,team=data"
    2024-06-01T12:00:00Z,gpu_pcie_throughput_mbps,GPU-c9d0e1f2,nvidia0,550e8400-e29b-41d4-a716-446655440012,NVIDIA L40S,node-03,batch-processor,batch-pod-0,data-eng,12800,"job=etl-pipeline,team=data"

pvc:
  enabled: false
  claimName: streamer-csv-data
